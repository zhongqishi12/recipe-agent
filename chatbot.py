# chatbot_gradio.py
import asyncio
from typing import Dict, Any
from dotenv import load_dotenv
import gradio as gr

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
from nodes.graph import get_chat_app


async def run_recipe_graph_stream(query: str):
    inputs = {"user_raw_query": query}
    app = get_chat_app()
    async for state in app.astream(inputs):
        yield state.get("messages", [])


def chat_interface_stream(user_message, history):
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        async def run_stream():
            async for messages in run_recipe_graph_stream(user_message):
                assistant_msgs = [m["content"] for m in messages if m.get("role") == "assistant"]
                if assistant_msgs:
                    # æŠŠå¤šæ¡åŠ©æ‰‹æ¶ˆæ¯åˆå¹¶
                    yield "\n\n".join(assistant_msgs)

        # ç”¨ iterator é©±åŠ¨ async generatorï¼Œè€Œä¸æ˜¯ asyncio.run
        agen = run_stream()
        while True:
            try:
                result = loop.run_until_complete(agen.__anext__())
                yield result
            except StopAsyncIteration:
                break

    except Exception as e:
        yield f"ç¨‹åºå‡ºç°é”™è¯¯: {e}"


async def async_generator_to_list(async_gen):
    """å°†å¼‚æ­¥ç”Ÿæˆå™¨è½¬æ¢ä¸ºåˆ—è¡¨"""
    results = []
    async for item in async_gen:
        results.append(item)
    return results


def chat_interface(user_message, history):
    """
    éæµå¼ç‰ˆæœ¬ï¼ˆå¤‡ç”¨ï¼‰
    """
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        async def get_final_result():
            final_messages = None
            async for messages in run_recipe_graph_stream(user_message):
                final_messages = messages
            return final_messages

        final_messages = loop.run_until_complete(get_final_result())

        if final_messages:
            # æå–æ‰€æœ‰åŠ©æ‰‹æ¶ˆæ¯
            assistant_messages = [
                msg["content"] for msg in final_messages
                if msg.get("role") == "assistant"
            ]
            return "\n\n".join(assistant_messages)
        else:
            return "æŠ±æ­‰ï¼Œæˆ‘æ²¡èƒ½ç”Ÿæˆé£Ÿè°±è®¡åˆ’ï¼Œå¯èƒ½åœ¨å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°äº†é—®é¢˜ã€‚"

    except Exception as e:
        return f"ç¨‹åºå‡ºç°é”™è¯¯: {e}"


if __name__ == "__main__":
    with gr.Blocks() as demo:
        gr.Markdown("## ğŸ¥ª æ™ºèƒ½é£Ÿè°±åŠ©æ‰‹\nè¾“å…¥ä½ çš„éœ€æ±‚ï¼ŒAI ä¼šå¸®ä½ è§„åˆ’èœå•ï¼")
        chatbot = gr.Chatbot(height=500, type="messages")
        msg = gr.Textbox(placeholder="è¯·è¾“å…¥ä½ çš„é£Ÿè°±éœ€æ±‚...")
        clear = gr.Button("æ¸…ç©ºå¯¹è¯")


        def respond_stream(user_message, chat_history):
            """æµå¼å“åº”å‡½æ•°"""
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            chat_history.append({"role": "user", "content": user_message})

            # æ·»åŠ ç©ºçš„åŠ©æ‰‹æ¶ˆæ¯ï¼Œç”¨äºæ›´æ–°
            chat_history.append({"role": "assistant", "content": ""})

            # æµå¼æ›´æ–°åŠ©æ‰‹æ¶ˆæ¯
            for progress_text in chat_interface_stream(user_message, chat_history):
                chat_history[-1]["content"] = progress_text
                yield "", chat_history


        def respond_simple(user_message, chat_history):
            """ç®€å•å“åº”å‡½æ•°"""
            reply = chat_interface(user_message, chat_history)
            chat_history.append({"role": "user", "content": user_message})
            chat_history.append({"role": "assistant", "content": reply})
            return "", chat_history


        # ä½¿ç”¨æµå¼ç‰ˆæœ¬
        msg.submit(respond_stream, [msg, chatbot], [msg, chatbot])
        clear.click(lambda: [], None, chatbot, queue=False)

    demo.launch(server_name="0.0.0.0", server_port=7860)